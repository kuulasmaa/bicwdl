#!/bin/bash

#SBATCH --job-name=slurm_env
#SBATCH --ntasks=1
#SBATCH --cpus-per-task 1
#SBATCH --partition serial
#SBATCH --time 00:05:00

echo "==============================================================================="
echo "INPUT ENVIRONMENT VARIABLES: (Upon startup, sbatch will read and handle the options set in the following environment variables. Note that environment variables will override any options set in a batch script, and command line options will override any enviro                                                     nment variables.)"
echo "==============================================================================="
echo "SBATCH_ACCOUNT: (Same as -A, --account)"
echo " -> $SBATCH_ACCOUNT"
echo "SBATCH_ACCTG_FREQ: (Same as --acctg-freq)"
echo " -> $SBATCH_ACCTG_FREQ"
echo "SBATCH_ARRAY_INX: (Same as -a, --array)"
echo " -> $SBATCH_ARRAY_INX"
echo "SBATCH_BATCH: (Same as --batch)"
echo " -> $SBATCH_BATCH"
echo "SBATCH_CHECKPOINT: (Same as --checkpoint)"
echo " -> $SBATCH_CHECKPOINT"
echo "SBATCH_CLUSTERS: (Same as --clusters)"
echo " -> $SBATCH_CLUSTERS"
echo "SLURM_CLUSTERS: (Same as --clusters)"
echo " -> $SLURM_CLUSTERS"
echo "SBATCH_CONSTRAINT: (Same as -C, --constraint)"
echo " -> $SBATCH_CONSTRAINT"
echo "SBATCH_CORE_SPEC: (Same as --core-spec)"
echo " -> $SBATCH_CORE_SPEC"
echo "SBATCH_CPUS_PER_GPU: (Same as --cpus-per-gpu)"
echo " -> $SBATCH_CPUS_PER_GPU"
echo "SBATCH_DEBUG: (Same as -v, --verbose)"
echo " -> $SBATCH_DEBUG"
echo "SBATCH_DELAY_BOOT: (Same as --delay-boot)"
echo " -> $SBATCH_DELAY_BOOT"
echo "SBATCH_DISTRIBUTION: (Same as -m, --distribution)"
echo " -> $SBATCH_DISTRIBUTION"
echo "SBATCH_EXCLUSIVE: (Same as --exclusive)"
echo " -> $SBATCH_EXCLUSIVE"
echo "SBATCH_EXPORT: (Same as --export)"
echo " -> $SBATCH_EXPORT"
echo "SBATCH_GET_USER_ENV: (Same as --get-user-env)"
echo " -> $SBATCH_GET_USER_ENV"
echo "SBATCH_GPUS: (Same as -G, --gpus)"
echo " -> $SBATCH_GPUS"
echo "SBATCH_GPU_BIND: (Same as --gpu-bind)"
echo " -> $SBATCH_GPU_BIND"
echo "SBATCH_GPU_FREQ: (Same as --gpu-freq)"
echo " -> $SBATCH_GPU_FREQ"
echo "SBATCH_GPUS_PER_NODE: (Same as --gpus-per-node)"
echo " -> $SBATCH_GPUS_PER_NODE"
echo "SBATCH_GPUS_PER_TASK: (Same as --gpus-per-task SBATCH_GRES Same as --gres)"
echo " -> $SBATCH_GPUS_PER_TASK"
echo "SBATCH_GRES_FLAGS: (Same as --gres-flags)"
echo " -> $SBATCH_GRES_FLAGS"
echo "SBATCH_HINT: (Same as --hint)"
echo " -> $SBATCH_HINT"
echo "SLURM_HINT: (Same as --hint)"
echo " -> $SLURM_HINT"
echo "SBATCH_IGNORE_PBS: (Same as --ignore-pbs)"
echo " -> $SBATCH_IGNORE_PBS"
echo "SBATCH_JOB_NAME: (Same as -J, --job-name)"
echo " -> $SBATCH_JOB_NAME"
echo "SBATCH_MEM_BIND: (Same as --mem-bind)"
echo " -> $SBATCH_MEM_BIND"
echo "SBATCH_MEM_PER_GPU: (Same as --mem-per-gpu)"
echo " -> $SBATCH_MEM_PER_GPU"
echo "SBATCH_NETWORK: (Same as --network)"
echo " -> $SBATCH_NETWORK"
echo "SBATCH_NO_KILL: (Same as -k, --no-kill)"
echo " -> $SBATCH_NO_KILL"
echo "SBATCH_NO_REQUEUE: (Same as --no-requeue)"
echo " -> $SBATCH_NO_REQUEUE"
echo "SBATCH_OPEN_MODE: (Same as --open-mode)"
echo " -> $SBATCH_OPEN_MODE"
echo "SBATCH_OVERCOMMIT: (Same as -O, --overcommit)"
echo " -> $SBATCH_OVERCOMMIT"
echo "SBATCH_PARTITION: (Same as -p, --partition)"
echo " -> $SBATCH_PARTITION"
echo "SBATCH_POWER: (Same as --power)"
echo " -> $SBATCH_POWER"
echo "SBATCH_PROFILE: (Same as --profile)"
echo " -> $SBATCH_PROFILE"
echo "SBATCH_QOS: (Same as --qos)"
echo " -> $SBATCH_QOS"
echo "SBATCH_RESERVATION: (Same as --reservation)"
echo " -> $SBATCH_RESERVATION"
echo "SBATCH_REQ_SWITCH: (When a tree topology is used, this defines the maximum count of switches desired for the job allocation and optionally the maximum time to wait for that number of switches. See --switches)"
echo " -> $SBATCH_REQ_SWITCH"
echo "SBATCH_REQUEUE: (Same as --requeue)"
echo " -> $SBATCH_REQUEUE"
echo "SBATCH_SIGNAL: (Same as --signal)"
echo " -> $SBATCH_SIGNAL"
echo "SBATCH_SPREAD_JOB: (Same as --spread-job)"
echo " -> $SBATCH_SPREAD_JOB"
echo "SBATCH_THREAD_SPEC: (Same as --thread-spec)"
echo " -> $SBATCH_THREAD_SPEC"
echo "SBATCH_TIMELIMIT: (Same as -t, --time)"
echo " -> $SBATCH_TIMELIMIT"
echo "SBATCH_USE_MIN_NODES: (Same as --use-min-nodes)"
echo " -> $SBATCH_USE_MIN_NODES"
echo "SBATCH_WAIT: (Same as -W, --wait)"
echo " -> $SBATCH_WAIT"
echo "SBATCH_WAIT_ALL_NODES: (Same as --wait-all-nodes)"
echo " -> $SBATCH_WAIT_ALL_NODES"
echo "SBATCH_WAIT4SWITCH: (Max time waiting for requested switches. See --switches)"
echo " -> $SBATCH_WAIT4SWITCH"
echo "SBATCH_WCKEY: (Same as --wckey)"
echo " -> $SBATCH_WCKEY"
echo "SLURM_CONF: (The location of the Slurm configuration file.)"
echo " -> $SLURM_CONF"
echo "SLURM_EXIT_ERROR: (Specifies the exit code generated when a Slurm error occurs (e.g. invalid options). This can be used by a script to distinguish application exit codes from various Slurm error conditions.)"
echo " -> $SLURM_EXIT_ERROR"
echo "SLURM_STEP_KILLED_MSG_NODE_ID: (SLURM_STEP_KILLED_MSG_NODE_ID=ID. If set, only the specified node will log when the job or step are killed by a signal.)"
echo " -> $SLURM_STEP_KILLED_MSG_NODE_ID"
echo "==============================================================================="
echo ""
echo "==============================================================================="
echo "OUTPUT ENVIRONMENT VARIABLES: (The Slurm controller will set the following variables in the environment of the batch script.)"
echo "==============================================================================="
echo "SBATCH_MEM_BIND: (Set to value of the --mem-bind option.)"
echo " -> $SBATCH_MEM_BIND"
echo "SBATCH_MEM_BIND_LIST: (Set to bit mask used for memory binding.)"
echo " -> $SBATCH_MEM_BIND_LIST"
echo "SBATCH_MEM_BIND_PREFER: (Set to "prefer" if the --mem-bind option includes the prefer option.)"
echo " -> $SBATCH_MEM_BIND_PREFER"
echo "SBATCH_MEM_BIND_TYPE: (Set to the memory binding type specified with the --mem-bind option. Possible values are "none", "rank", "map_map", "mask_mem" and "local".)"
echo " -> $SBATCH_MEM_BIND_TYPE"
echo "SBATCH_MEM_BIND_VERBOSE: (Set to "verbose" if the --mem-bind option includes the verbose option. Set to "quiet" otherwise.)"
echo " -> $SBATCH_MEM_BIND_VERBOSE"
echo "SLURM_*_PACK_GROUP_#: (For a heterogeneous job allocation, the environment variables are set separately for each component.)"
echo " -> $SLURM_*_PACK_GROUP_#"
echo "SLURM_ARRAY_TASK_COUNT: (Total number of tasks in a job array.)"
echo " -> $SLURM_ARRAY_TASK_COUNT"
echo "SLURM_ARRAY_TASK_ID: (Job array ID (index) number.)"
echo " -> $SLURM_ARRAY_TASK_ID"
echo "SLURM_ARRAY_TASK_MAX: (Job array's maximum ID (index) number.)"
echo " -> $SLURM_ARRAY_TASK_MAX"
echo "SLURM_ARRAY_TASK_MIN: (Job array's minimum ID (index) number.)"
echo " -> $SLURM_ARRAY_TASK_MIN"
echo "SLURM_ARRAY_TASK_STEP: (Job array's index step size.)"
echo " -> $SLURM_ARRAY_TASK_STEP"
echo "SLURM_ARRAY_JOB_ID: (Job array's master job ID number.)"
echo " -> $SLURM_ARRAY_JOB_ID"
echo "SLURM_CLUSTER_NAME: (Name of the cluster on which the job is executing.)"
echo " -> $SLURM_CLUSTER_NAME"
echo "SLURM_CPUS_ON_NODE: (Number of CPUS on the allocated node.)"
echo " -> $SLURM_CPUS_ON_NODE"
echo "SLURM_CPUS_PER_GPU: (Number of CPUs requested per allocated GPU. Only set if the --cpus-per-gpu option is specified.)"
echo " -> $SLURM_CPUS_PER_GPU"
echo "SLURM_CPUS_PER_TASK: (Number of cpus requested per task. Only set if the --cpus-per-task option is specified.)"
echo " -> $SLURM_CPUS_PER_TASK"
echo "SLURM_DISTRIBUTION: (Same as -m, --distribution)"
echo " -> $SLURM_DISTRIBUTION"
echo "SLURM_GPUS: (Number of GPUs requested. Only set if the -G, --gpus option is specified.)"
echo " -> $SLURM_GPUS"
echo "SLURM_GPU_BIND: (Requested binding of tasks to GPU. Only set if the --gpu-bind option is specified.)"
echo " -> $SLURM_GPU_BIND"
echo "SLURM_GPU_FREQ: (Requested GPU frequency. Only set if the --gpu-freq option is specified.)"
echo " -> $SLURM_GPU_FREQ"
echo "SLURM_GPUS_PER_NODE: (Requested GPU count per allocated node. Only set if the --gpus-per-node option is specified.)"
echo " -> $SLURM_GPUS_PER_NODE"
echo "SLURM_GPUS_PER_SOCKET: (Requested GPU count per allocated socket. Only set if the --gpus-per-socket option is specified.)"
echo " -> $SLURM_GPUS_PER_SOCKET"
echo "SLURM_GPUS_PER_TASK: (Requested GPU count per allocated task. Only set if the --gpus-per-task option is specified.)"
echo " -> $SLURM_GPUS_PER_TASK"
echo "SLURM_GTIDS: (Global task IDs running on this node. Zero origin and comma separated.)"
echo " -> $SLURM_GTIDS"
echo "SLURM_JOB_ACCOUNT: (Account name associated of the job allocation.)"
echo " -> $SLURM_JOB_ACCOUNT"
echo "SLURM_JOB_ID: (and SLURM_JOBID for backwards compatibility) (The ID of the job allocation.)"
echo " -> $SLURM_JOB_ID"
echo "SLURM_JOB_CPUS_PER_NODE: (Count of processors available to the job on this node. Note the select/linear plugin allocates entire nodes to jobs, so the value indicates the total count of CPUs on the node. The select/cons_res plugin allocates individual process                                                     ors to jobs, so this number indicates the number of processors on this node allocated to the job.)"
echo " -> $SLURM_JOB_CPUS_PER_NODE"
echo "SLURM_JOB_DEPENDENCY: (Set to value of the --dependency option.)"
echo " -> $SLURM_JOB_DEPENDENCY"
echo "SLURM_JOB_NAME: (Name of the job.)"
echo " -> $SLURM_JOB_NAME"
echo "SLURM_JOB_NODELIST: (and SLURM_NODELIST for backwards compatibility) (List of nodes allocated to the job.)"
echo " -> $SLURM_JOB_NODELIST"
echo "SLURM_JOB_NUM_NODES: (and SLURM_NNODES for backwards compatibility) (Total number of nodes in the job's resource allocation.)"
echo " -> $SLURM_JOB_NUM_NODES"
echo "SLURM_JOB_PARTITION: (Name of the partition in which the job is running.)"
echo " -> $SLURM_JOB_PARTITION"
echo "SLURM_JOB_QOS: (Quality Of Service (QOS) of the job allocation.)"
echo " -> $SLURM_JOB_QOS"
echo "SLURM_JOB_RESERVATION: (Advanced reservation containing the job allocation, if any.)"
echo " -> $SLURM_JOB_RESERVATION"
echo "SLURM_LOCALID: (Node local task ID for the process within a job.)"
echo " -> $SLURM_LOCALID"
echo "SLURM_MEM_PER_CPU: (Same as --mem-per-cpu)"
echo " -> $SLURM_MEM_PER_CPU"
echo "SLURM_MEM_PER_GPU: (Requested memory per allocated GPU. Only set if the --mem-per-gpu option is specified.)"
echo " -> $SLURM_MEM_PER_GPU"
echo "SLURM_MEM_PER_NODE: (Same as --mem)"
echo " -> $SLURM_MEM_PER_NODE"
echo "SLURM_NODE_ALIASES: (Sets of node name, communication address and hostname for nodes allocated to the job from the cloud. Each element in the set if colon separated and each set is comma separated. For example: SLURM_NODE_ALIASES=ec0:1.2.3.4:foo,ec1:1.2.3.5:                                                     bar)"
echo " -> $SLURM_NODE_ALIASES"
echo "SLURM_NODEID: (ID of the nodes allocated.)"
echo " -> $SLURM_NODEID"
echo "SLURM_NTASKS: (and SLURM_NPROCS for backwards compatibility) (Same as -n, --ntasks)"
echo " -> $SLURM_NTASKS"
echo "SLURM_NTASKS_PER_CORE: (Number of tasks requested per core. Only set if the --ntasks-per-core option is specified.)"
echo " -> $SLURM_NTASKS_PER_CORE"
echo "SLURM_NTASKS_PER_NODE: (Number of tasks requested per node. Only set if the --ntasks-per-node option is specified.)"
echo " -> $SLURM_NTASKS_PER_NODE"
echo "SLURM_NTASKS_PER_SOCKET: (Number of tasks requested per socket. Only set if the --ntasks-per-socket option is specified.)"
echo " -> $SLURM_NTASKS_PER_SOCKET"
echo "SLURM_PACK_SIZE: (Set to count of components in heterogeneous job.)"
echo " -> $SLURM_PACK_SIZE"
echo "SLURM_PRIO_PROCESS: (The scheduling priority (nice value) at the time of job submission. This value is propagated to the spawned processes.)"
echo " -> $SLURM_PRIO_PROCESS"
echo "SLURM_PROCID: (The MPI rank (or relative process ID) of the current process)"
echo " -> $SLURM_PROCID"
echo "SLURM_PROFILE: (Same as --profile)"
echo " -> $SLURM_PROFILE"
echo "SLURM_RESTART_COUNT: (If the job has been restarted due to system failure or has been explicitly requeued, this will be sent to the number of times the job has been restarted.)"
echo " -> $SLURM_RESTART_COUNT"
echo "SLURM_SUBMIT_DIR: (The directory from which sbatch was invoked or, if applicable, the directory specified by the -D, --chdir option.)"
echo " -> $SLURM_SUBMIT_DIR"
echo "SLURM_SUBMIT_HOST: (The hostname of the computer from which sbatch was invoked.)"
echo " -> $SLURM_SUBMIT_HOST"
echo "SLURM_TASKS_PER_NODE: (Number of tasks to be initiated on each node. Values are comma separated and in the same order as SLURM_JOB_NODELIST. If two or more consecutive nodes are to have the same task count, that count is followed by '(x#)' where '#' is the r                                                     epetition count. For example, 'SLURM_TASKS_PER_NODE=2(x3),1' indicates that the first three nodes will each execute three tasks and the fourth node will execute one task.)"
echo " -> $SLURM_TASKS_PER_NODE"
echo "SLURM_TASK_PID: (The process ID of the task being started.)"
echo " -> $SLURM_TASK_PID"
echo "SLURM_TOPOLOGY_ADDR: (This is set only if the system has the topology/tree plugin configured. The value will be set to the names network switches which may be involved in the job's communications from the system's top level switch down to the leaf switch and                                                      ending with node name. A period is used to separate each hardware component name.)"
echo " -> $SLURM_TOPOLOGY_ADDR"
echo "SLURM_TOPOLOGY_ADDR_PATTERN: (This is set only if the system has the topology/tree plugin configured. The value will be set component types listed in SLURM_TOPOLOGY_ADDR. Each component will be identified as either "switch" or "node". A period is used to sep                                                     arate each hardware component type. (SLURMD_NODENAME)Name of the node running the job script.)"
echo " -> $SLURM_TOPOLOGY_ADDR_PATTERN"
echo "==============================================================================="
echo ""
echo "==============================================================================="
echo "OTHER ENVIRONMENT VARIABLES"
echo "==============================================================================="
echo "TMPDIR"
echo " ->  $TMPDIR"
echo "SCRATCHDIR"
echo " ->  $SCRATCHDIR"
echo "==============================================================================="
